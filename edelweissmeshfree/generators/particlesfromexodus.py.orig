# -*- coding: utf-8 -*-
#  ---------------------------------------------------------------------
#
#  _____    _      _              _
# | ____|__| | ___| |_      _____(_)___ ___
# |  _| / _` |/ _ \ \ \ /\ / / _ \ / __/ __|
# | |__| (_| |  __/ |\ V  V /  __/ \__ \__ \
# |_____\__,_|\___|_| \_/\_/_\___|_|___/___/
# |  \/  | ___  ___| |__  / _|_ __ ___  ___
# | |\/| |/ _ \/ __| '_ \| |_| '__/ _ \/ _ \
# | |  | |  __/\__ \ | | |  _| | |  __/  __/
# |_|  |_|\___||___/_| |_|_| |_|  \___|\___|
#
#
#  Unit of Strength of Materials and Structural Analysis
#  University of Innsbruck,
#
#  Research Group for Computational Mechanics of Materials
#  Institute of Structural Engineering, BOKU University, Vienna
#
#  2023 - today
#
#  Matthias Neuner |  matthias.neuner@boku.ac.at
#  Thomas Mader    |  thomas.mader@bokut.ac.at
#
#  This file is part of EdelweissMeshfree.
#
#  This library is free software; you can redistribute it and/or
#  modify it under the terms of the GNU Lesser General Public
#  License as published by the Free Software Foundation; either
#  version 2.1 of the License, or (at your option) any later version.
#
#  The full text of the license can be found in the file LICENSE.md at
#  the top level directory of EdelweissMeshfree.
#  ---------------------------------------------------------------------


import netCDF4
import numpy as np
from edelweissfe.journal.journal import Journal
from edelweissfe.surfaces.entitybasedsurface import EntityBasedSurface

from edelweissmpm.models.mpmmodel import MPMModel
from edelweissmpm.particles.base.baseparticle import BaseParticle
from edelweissmpm.sets.particleset import ParticleSet

HEX8_EXO_TO_ABAQUS = {
    # ----------------------------------------------------------------------
    # DIRECT MAPPING: EXODUS SIDE ID -> ABAQUS FACE ID
    # ----------------------------------------------------------------------
    1: 3,
    2: 4,
    3: 5,
    4: 6,
    5: 1,
    6: 2,
}

ELEMENT_SIDE_MAP = {
    "HEX8": HEX8_EXO_TO_ABAQUS,
    "HEX": HEX8_EXO_TO_ABAQUS,
}


def generateParticlesFromExodus(
    model: MPMModel,
    journal: Journal,
    filename: str,
    elementTypeToParticleClass: dict[str, BaseParticle],
    name: str = "exo_import",
    firstParticleNumber: int = 1,
):
    """Generates particles in the MPMModel from an Exodus mesh file."""

    journal.message(f"Reading Exodus mesh (Pure NetCDF) from: {filename}", "exo", 1)

    nc = netCDF4.Dataset(filename, "r")

    # ------------------------------------------------------------------
    # 1) READ COORDINATES
    # ------------------------------------------------------------------
    x = nc.variables["coordx"][:]
    y = nc.variables["coordy"][:]
    if "coordz" in nc.variables:
        z = nc.variables["coordz"][:]
    else:
        z = np.zeros_like(x)

    nodes = np.column_stack((x, y, z))

    # ------------------------------------------------------------------
    # 2) READ ELEMENT BLOCKS & CREATE PARTICLES
    # ------------------------------------------------------------------
    currentParticleNumber = firstParticleNumber
    particles = {}

    # Lookup lists for O(1) access later
    global_ordered_particles = []
    global_element_types = []
    element_block_membership = {}

    # --- NEW: Arrays for building Inverse Map (Node -> Particles) ---
    # We store raw arrays here to perform a fast vectorized sort later
    inv_map_nodes = []  # List of arrays of node indices
    inv_map_elems = []  # List of arrays of element indices (internal index)
    global_elem_counter = 0

    # Get Block IDs
    if "eb_prop1" in nc.variables:
        eb_ids = nc.variables["eb_prop1"][:]
    else:
        dim_names = [d for d in nc.dimensions.keys() if d.startswith("num_el_in_blk")]
        eb_ids = range(1, len(dim_names) + 1)

    # Get Block Names
    eb_names = []
    if "eb_names" in nc.variables:
        for c in nc.variables["eb_names"][:]:
            n = c.tobytes().decode("utf-8").strip("\x00").strip()
            eb_names.append(n)

    for i, blk_id in enumerate(eb_ids):
        conn_var_name = f"connect{blk_id}"

        if conn_var_name not in nc.variables:
            journal.message(f"Skipping Block {blk_id} (connectivity variable not found)", "exo", 2)
            continue

        # Raw connectivity: (Num_Elem_In_Block, Nodes_Per_Elem)
        # Convert to 0-based immediately
        block_conn = nc.variables[conn_var_name][:] - 1
        num_elems_in_block = block_conn.shape[0]

        # Block Name
        if i < len(eb_names) and eb_names[i]:
            block_name = eb_names[i]
        else:
            block_name = f"block_{blk_id}"

        # Element Type
        num_nodes_per_elem = block_conn.shape[1]
        if num_nodes_per_elem == 8:
            elem_type = "HEX8"
        elif num_nodes_per_elem == 4:
            elem_type = "TET4"
        else:
            elem_type = f"UNKNOWN_{num_nodes_per_elem}"
            raise NotImplementedError(f"Element type with {num_nodes_per_elem} nodes not supported.")

        element_block_membership[block_name] = []

        # Check support
        is_supported = True
        elem_type_key = elem_type

        if elem_type not in elementTypeToParticleClass:
            if "hexahedron" in elementTypeToParticleClass and elem_type == "HEX8":
                elem_type_key = "hexahedron"
            elif elem_type in elementTypeToParticleClass:
                elem_type_key = elem_type
            else:
                journal.message(f"Skipping Block {block_name} (Type {elem_type} not supported)", "exo", 2)
                is_supported = False

        if not is_supported:
            # Pad global lists to maintain index alignment for Side Sets/Node Sets
            for _ in range(num_elems_in_block):
                global_ordered_particles.append(None)
                global_element_types.append(None)
            global_elem_counter += num_elems_in_block
            continue

        ParticleClass = elementTypeToParticleClass[elem_type_key]

        # --- Create Particles ---
        for elem_nodes_indices in block_conn:
            el_coords = nodes[elem_nodes_indices]
            p = ParticleClass(currentParticleNumber, el_coords)

            particles[currentParticleNumber] = p
            element_block_membership[block_name].append(currentParticleNumber)

            global_ordered_particles.append(p)
            global_element_types.append(elem_type)
            currentParticleNumber += 1

        # --- Accumulate data for Inverse Map ---
        # 1. Flatten the nodes for this block
        inv_map_nodes.append(block_conn.flatten())
        # 2. Create corresponding element indices (repeated for each node)
        # These are internal indices [0, 1, 2...] matching global_ordered_particles
        current_indices = np.arange(global_elem_counter, global_elem_counter + num_elems_in_block)
        repeated_indices = np.repeat(current_indices, num_nodes_per_elem)
        inv_map_elems.append(repeated_indices)

        global_elem_counter += num_elems_in_block

    # Register particles
    for pid, p in particles.items():
        model.particles[pid] = p

    model.particleSets[f"{name}_all"] = ParticleSet(f"{name}_all", list(particles.values()))

    journal.message(f"Created {len(particles)} particles.", "exo", 1)

    # ------------------------------------------------------------------
    # 3) CREATE BLOCK SETS
    # ------------------------------------------------------------------
    for block_name, pid_list in element_block_membership.items():
        if pid_list:
            model.particleSets[f"{name}_block_{block_name}"] = ParticleSet(
                f"{name}_block_{block_name}", [model.particles[pid] for pid in pid_list]
            )

    # 4) CREATE SIDE SETS (Direct Map)
    # ------------------------------------------------------------------
    journal.message("Reading side sets (Direct Map)...", "exo", 1)

    if "num_side_sets" in nc.dimensions:
        # Get IDs
        if "ss_prop1" in nc.variables:
            ss_ids = nc.variables["ss_prop1"][:]
        else:
            ss_ids = range(1, len(nc.dimensions["num_side_sets"]) + 1)

        # Get Names
        ss_names = []
        if "ss_names" in nc.variables:
            for c in nc.variables["ss_names"][:]:
                n = c.tobytes().decode("utf-8").strip("\x00").strip()
                ss_names.append(n)

        for i, ss_id in enumerate(ss_ids):
            if i < len(ss_names) and ss_names[i]:
                setname = ss_names[i]
            else:
                setname = f"sideset_{ss_id}"

            elem_var = f"elem_ss{ss_id}"
            side_var = f"side_ss{ss_id}"

            if elem_var not in nc.variables:
                continue

            ss_elems = nc.variables[elem_var][:]
            ss_sides = nc.variables[side_var][:]

            surface_entries = {}

            for raw_elem_id, raw_side_id in zip(ss_elems, ss_sides):
                e_idx = raw_elem_id - 1

                if e_idx < 0 or e_idx >= len(global_ordered_particles):
                    continue

                p = global_ordered_particles[e_idx]
                if p is None:
                    continue

                e_type = global_element_types[e_idx]
                mapping = ELEMENT_SIDE_MAP.get(e_type)

                if mapping and raw_side_id in mapping:
                    aba_face_id = mapping[raw_side_id]

                    if aba_face_id not in surface_entries:
                        surface_entries[aba_face_id] = []
                    surface_entries[aba_face_id].append(p)

            if surface_entries:
                model.surfaces[f"{name}_sideset_{setname}"] = EntityBasedSurface(
                    f"{name}_sideset_{setname}", surface_entries
                )
                for fid, plist in surface_entries.items():
                    journal.message(f"Sideset '{setname}': Face {fid}, count={len(plist)}", "exo", 1)

    nc.close()
    return model
